title:
Invalid argument error

user:
Koratun

status:
closed

labels:
2.6.0
comp:keras
stat:awaiting response
type:bug

contributors:
jpienaar
ebrevdo

description:
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10

TensorFlow installed from (source or binary):
pip install tensorflow

TensorFlow version (use command below):
2.6.0

Python version:
3.7

CUDA/cuDNN version:
11.3

GPU model and memory:
NVIDIA 2060 SUPER, compute capability: 7.5
6010MB

I am trying to create a model that takes two images (one taken right after the other) and train it so that it can predict how much movement has occurred. I use a smaller model that processes one image at a time, then concatenate the two outputs in a larger model.

I tried testing it and the model compiles just fine, but it crashes when I call fit() and gives me an invalid argument error.

2021-10-11 10:46:28.321065: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)
2021-10-11 10:46:29.319124: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at transpose_op.cc:143 : Invalid argument: transpose expects a vector of size 5. But input(1) is a vTraceback (most recent call last):
2021-10-11 10:46:29.319416: W tensorflow/core/framework/op_kernel.cc:1692] OP_REQUIRES failed at transpose_op.cc:143 : Invalid argument: transpose expects a vector of size 5. But input(1) is a vTraceback (most recent call last):
  File "d:/.../Deep Sight/deep_sight.py", line 155, in <module>
    main()
  File "d:/.../Deep Sight/deep_sight.py", line 150, in main
    final_model.fit(train_data, epochs=5)
  File "C:\Users\...\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\engine\training.py", line 1184, in fit
    tmp_logs = self.train_function(iterator)
  File "C:\Users\...\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\eager\def_function.py", line 885, in __call__
    result = self._call(*args, **kwds)
  File "C:\Users\...\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\eager\def_function.py", line 950, in _call
    return self._stateless_fn(*args, **kwds)
  File "C:\Users\...\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py", line 3040, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File "C:\Users\...\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py", line 1964, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "C:\Users\...\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\eager\function.py", line 596, in call
    ctx=ctx)
  File "C:\Users\...\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\eager\execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  transpose expects a vector of size 5. But input(1) is a vector of size 4
         [[{{node gradient_tape/model_1/model/conv2d/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]
         [[Func/mean_squared_error/cond/then/_0/input/_29/_48]]
  (1) Invalid argument:  transpose expects a vector of size 5. But input(1) is a vector of size 4
         [[{{node gradient_tape/model_1/model/conv2d/Conv2D/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_3095]

Function call stack:
train_function -> train_function
Standalone code to reproduce the issue
My batch size is 32 as defined in my dataset. I believe it has something to do with the squeeze method because in an earlier version of this model I did not use the squeeze or split methods and it ran perfectly fine. However, because my dataset is much larger now, I shifted to using tf.Datasets to input the data. This required me to input the 2 images together in a single tensor as the input.

The shape of my dataset is: (batch, features, labels) with the label being a scalar, and each feature being of shape: (2, 256, 256, 3)

def main():
    # Create model

    # Start with smaller model that processes the two images in the same way.
    single_image_input = keras.Input(shape=(256,256,3))

    image = layers.Conv2D(64, (3,3))(single_image_input)
    image = layers.LeakyReLU()(image)
    image = layers.BatchNormalization()(image)
    # Run through MaxPool2D to help the algorithm identify features in different areas of the image.
    # Has the effect of downsampling and cutting the dimensions in half.
    image = layers.MaxPool2D()(image)

    image = layers.Conv2D(128, (3, 3))(image)
    image = layers.LeakyReLU()(image)
    image = layers.BatchNormalization()(image)
    image = layers.Dropout(.3)(image)

    image_model = keras.Model(single_image_input, image)
    
    # Create larger model
    image_inputs = keras.Input(shape=(2,256,256,3))

    first_image, second_image = tf.split(image_inputs, num_or_size_splits=2, axis=0)
    first_image, second_image = tf.squeeze(first_image), tf.squeeze(second_image)

    image_outputs = [image_model(first_image), image_model(second_image)]
    model = layers.Concatenate()(image_outputs)

    model = layers.Flatten()(model)

    model = layers.Dense(128)(model)
    model = layers.LeakyReLU()(model)
    model = layers.BatchNormalization()(model)
    model = layers.Dropout(.3)(model)

    # Output is change in y-position of drone
    out_layer = layers.Dense(1, activation='linear')(model)

    final_model = keras.Model(image_inputs, out_layer)
    final_model.compile(loss="mse", optimizer=optimizers.Adam(lr=0.0003, beta_1=0.7))

    image_model.summary()

    final_model.summary()


    #Preprocess data
    print("Loading and processing data...")
    train_data = tf_load_data()

    #Train model
    final_model.fit(train_data, epochs=5)
