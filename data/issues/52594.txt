title:
Failed to invoke the interpreter with error: Provided data count XXX must match the required count 3.

user:
bias

status:
closed

contributor:
andyly
martinwicke

labels:
2.6.0
TFLiteConverter
type:bug

description:
1. System information
OSX 11.5.2, iOS 14.7.1, CentOS 8.4.2105
TensorFlow v2.6.0 custom built for server (CentOS 8.4.2105)
TensorFlow library 'TensorFlowLiteSwift', '~> 2.6'
The CentOS custom built tensorflow was built with the following optimization flags:

-march=native -msse4_1 -msse4_2 -mssse3 -mcx16 -mpopcnt
On the CentOS 8 box I successfully trained a custom model using faster_rcnn_resnet152_v1 for it's configuration. I'm able to run the model on images and mp4 files successfully.

I converted the model on the CentOS box for tflite.

I copied the model into the tensorflow/examples/tree/master/lite/examples/object_detection/ios example project and updated the Podfile to use tflite 2.6.

2. Code
import tensorflow as tf

saved_model_dir = "exported-models/barbell_3/saved_model"

# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
]

tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
ModelDataHandler.swift
Case 1

  // MARK: Model parameters
  let batchSize = 1
  let inputChannels = 3
  let inputWidth = 1024
  let inputHeight = 1024
Case 2

  // MARK: Model parameters
  let batchSize = 1
  let inputChannels = 3
  let inputWidth = 1
  let inputHeight = 1
3. Failure after conversion
Case 1
Interpreter can't load model
Failed to invoke the interpreter with error: Provided data count 3145728 must match the required count 3.
Note 1024 * 1024 * 3 = 3145728

Note the netron graph entry point shows the input should be 1x1x1=3 followed by a while loop whose 3rd element is (1x1024x1024x3).

Presumably, these are the correct parameters however see case 2.

Case 2
If I set the inputWidth and inputHeight to 1x1 the interpreter loads, the app starts and then crashes with an Out of Memory error (in a popup window) - however, nothing is logged in the XCode console and no errors are given for tensorflow lite.

2021-10-20 09:28:46.565241-0500 ObjectDetection[723:92493] Initialized TensorFlow Lite runtime.
INFO: Initialized TensorFlow Lite runtime.
Is it the case that the correct parameters are inputHeight=1 and inputWidth=1 and that my model is using too much OS memory on the phone?

If that's true are there guidelines on which model training config params are suitable for phones (both iOS and Andriod)? That is, models with better input size and hidden layer size etc?

4. (optional) RNN conversion support
5. (optional) Any other info / logs